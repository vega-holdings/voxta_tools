---
id: 4WQtU93tQkfpY4U1JQcDV
slug: workaround-for-exllama-model-not-found-errors-4WQtU9
type: troubleshooting
title: Workaround for ExLlama Model Not Found Errors
topics:
  - troubleshooting
  - llm
keywords:
  - exllama
  - llama.cpp
  - model not found
  - error
  - stability
confidence: 0.8
authority: 0.2
contributor: sraura
sources:
  - messageId: "1389354195609718824"
    author: sraura
    timestamp: 2025-12-22T23:05:50.011Z
    url: ""
created: 2025-12-22T23:05:50.011Z
updated: 2025-12-22T23:05:50.011Z
---

# Workaround for ExLlama Model Not Found Errors

> Switch to llama.cpp if ExLlama throws 'model not found' errors.

## Answer

If you encounter 'model not found' errors or other stability issues with the ExLlama module, switch to the **llama.cpp** module. This is a known workaround that resolves these errors for many users.

---

*Extracted from Discord. Primary contributor: sraura*