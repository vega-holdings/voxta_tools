---
id: WRrrFeID0FMSgOOKXGrI1
slug: switching-inference-module-to-llamasharp-WRrrFe
type: tip
title: Switching Inference Module to LlamaSharp
topics:
  - configuration
  - llm
keywords:
  - LlamaSharp
  - ExLlamaV2
  - module
  - backend
  - switch
confidence: 0.6
authority: 0.2
contributor: minipasila
sources: []
created: 2025-12-22T23:42:00.510Z
updated: 2025-12-22T23:42:00.510Z
---

# Switching Inference Module to LlamaSharp

> Instructions for selecting the LlamaSharp module in the UI.

## Answer

To switch the inference backend (e.g., when moving from ExLlamaV2), locate the **Module** dropdown menu in the settings and select **LlamaSharp**. This is typically required when wanting to run GGUF models via the llama.cpp integration.

---

*Extracted from Discord. Primary contributor: minipasila*