---
id: R7ZEV2iqP7vCP5ZD_J1gY
slug: recommended-vram-for-local-hosting-R7ZEV2
type: qa
title: Recommended VRAM for local hosting
topics:
  - performance
  - setup
  - llm
keywords:
  - hardware requirements
  - VRAM
  - GPU
  - local hosting
  - memory
confidence: 0.85
authority: 0.2
contributor: a1os353
sources:
  - messageId: "1327744956479180993"
    author: a1os353
    timestamp: 2025-12-19T05:13:28.570Z
    url: ""
created: 2025-12-19T05:13:28.570Z
updated: 2025-12-19T05:13:28.570Z
---

# Recommended VRAM for local hosting

> 16GB VRAM is minimum for small models; 24GB VRAM is recommended for local hosting.

## Answer

When running AI models locally, **VRAM** (Video RAM on your Graphics Card) is the critical factor, distinct from system RAM.

*   **16 GB VRAM:** Possible with smaller models.
*   **24 GB VRAM:** Considered comfortable for running standard models effectively.

---

*Extracted from Discord. Primary contributor: a1os353*