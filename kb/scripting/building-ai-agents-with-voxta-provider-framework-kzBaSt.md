---
id: kzBaStLx5K-SrjjmhqljG
slug: building-ai-agents-with-voxta-provider-framework-kzBaSt
type: tip
title: Building AI Agents with Voxta Provider Framework
topics:
  - scripting
  - integrations
keywords:
  - provider framework
  - python
  - proxy
  - agent
  - openrouter
  - live broadcast
confidence: 0.8
authority: 0.2
contributor: djsoapyknuckles
sources:
  - messageId: "1323376309812068372"
    author: djsoapyknuckles
    timestamp: 2025-12-19T03:34:23.359Z
    url: ""
created: 2025-12-19T03:34:23.359Z
updated: 2025-12-19T03:34:23.359Z
---

# Building AI Agents with Voxta Provider Framework

> Use the Voxta provider framework to send messages on behalf of users for AI agent creation.

## Answer

Instead of using external Python scripts as proxies, you can utilize the **Voxta provider framework** to build AI agents (such as for live broadcasts). 

The framework allows you to send messages "as" or on behalf of a user to Voxta. This triggers the LLM (whether local or cloud-hosted like OpenRouter) to generate a response, keeping the architecture integrated within Voxta.

---

*Extracted from Discord. Primary contributor: djsoapyknuckles*