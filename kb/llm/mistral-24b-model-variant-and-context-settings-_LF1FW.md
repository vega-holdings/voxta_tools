---
id: _LF1FW0Pw6DnWYr5m3oPB
slug: mistral-24b-model-variant-and-context-settings-_LF1FW
type: tip
title: Mistral 24b Model Variant and Context Settings
topics:
  - llm
  - configuration
  - performance
keywords:
  - Mistral 24b
  - Dolphin Venice
  - context window
  - KoboldAI
  - RTX 5090
confidence: 0.8
authority: 0.2
contributor: storyline7673
sources:
  - messageId: "1427147441681072138"
    author: storyline7673
    timestamp: 2025-12-22T23:35:57.713Z
    url: ""
created: 2025-12-22T23:35:57.713Z
updated: 2025-12-22T23:35:57.713Z
---

# Mistral 24b Model Variant and Context Settings

> Recommendations for using the Dolphin Venice variant of Mistral 24b and appropriate context window settings.

## Answer

For users running **Mistral 24b** on high-end hardware (e.g., RTX 5090), the **Dolphin Venice** variant is recommended for improved story writing and character roleplay compared to the base model.

**Context Settings:**
*   **Recommended:** 16k - 32k tokens.
*   **Maximum:** 128k tokens (Note: Setting context this high may significantly reduce generation speed).

---

*Extracted from Discord. Primary contributor: storyline7673*