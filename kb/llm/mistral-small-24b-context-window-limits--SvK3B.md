---
id: -SvK3BWUAGef7qQaMFj_y
slug: mistral-small-24b-context-window-limits--SvK3B
type: reference
title: Mistral Small 24B Context Window Limits
topics:
  - llm
  - performance
keywords:
  - Mistral
  - Mistral-Small-24B
  - context window
  - 128k
  - 32k
  - tokens
confidence: 0.6
authority: 0.2
contributor: storyline7673
sources: []
created: 2025-12-22T23:43:23.290Z
updated: 2025-12-22T23:43:23.290Z
---

# Mistral Small 24B Context Window Limits

> Details on context window limits for specific Mistral Small 24B model versions.

## Answer

Different versions of the Mistral Small 24B model support different context window sizes:

* **Mistral-Small-3.1-24B-Instruct-2503** (and newer): Supports up to **128k tokens**.
* **Mistral-Small-24B-Instruct-2501**: Limited to **32k tokens**.

**Performance Note:** Utilizing the full context length (e.g., for long chat history or stories) can significantly slow down response generation.

---

*Extracted from Discord. Primary contributor: storyline7673*